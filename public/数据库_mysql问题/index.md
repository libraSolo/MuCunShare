# 数据库_MySQL


# 数据库_MySQL

# 索引

![请输入图片描述](./images/2024/09/2632954084.jpg)

## 索引的分类

* 按照索引结构
  1. B 树索引
     * 使用 B / B+ 树结构，高效的查找、插入和删除。
     * 适用于范围查询。
  2. 哈希索引
     * 使用哈希表实现，查找速度很快，不支持范围查询。
     * 适用于查找特定的值。
  3. 位图索引
     * 使用位图表示数据，适用于不同值较少的列
     * 适用于大规模查询。
* 按照索引的使用方式
  1. 主键索引
     * 基于表的主键创建的索引，自动创建，确保主键唯一性。
  2. 唯一索引
     * 确保索引列中的值唯一，不能包含重复值。
     * 可以用于非主键列。
  3. 普通索引
     * 没有唯一性，可以包含重复值。
     * 增加查询速度，不保证唯一性。
  4. 复合索引
     * 由多个列组成的索引，支持多列查询。
     * 提高查询的复杂性。
  5. 前缀索引
     * 包含某个列的前一部分。
     * 适用于储存字符/字节的列。
  6. 覆盖索引
     某个索引包含某个查询的所有列。
* 按照储存方式
  1. 聚集索引
     * 数据存储顺序与索引顺序相同，表中的数据行按照索引的顺序排列。
     * 每个表只能有一个聚集索引，因为数据行只能按一种方式存储。
  2. 非聚集索引
     * 索引与数据存储分开，索引包含指向数据行的指针。
     * 一个表可以有多个非聚集索引。
* 特殊类型
  1. 全文索引
     * 专门用于文本搜索，支持对文本数据进行复杂查询。
     * 常用于搜索引擎和内容管理系统。
  2. 空间索引
     * 用于地理信息系统（GIS）中的空间数据查询。

## 索引的代价

1. 索引本身需要存储起来，消耗磁盘空间。
2. 运行时，索引会加载到内存中，消耗内存空间。
3. 增删改的时候，同步维护索引，引入额外的消耗。

## B+ 树的优势

1. B+ 树的高度更低，所以查询耗时更少，性能更好。
2. B+ 树的叶子节点被串联起来了，更适合范围查询。
3. B+ 树的非叶子节点没有存放数据，所以可以放在**内存**中，查询性能更好。

## QA:数据库索引为什么用 B+ 树

与 B+ 树相比，**平衡二叉树**、**红黑树**在同等数据量下，高度更高，性能更差，而且它们会频繁执行再平衡过程，来保证树形结构平衡。

与 B+ 树相比，**跳表**在极端情况下会退化为链表，**平衡性差** ，而数据库查询需要一个可预期的查询时间，并且跳表需要更多的内存。

与 B+ 树相比，B 树的数据存储在全部节点中，**对范围查询不友好** 。非叶子节点存储了数据，**导致内存中难以放下全部非叶子节点** 。如果内存放不下非叶子节点，那么就意味着查询非叶子节点的时候都需要磁盘 IO。

## QA:为什么数据库不使用索引

**可能**的原因：

* 使用了 !=、Like 之类的查询
* 字段区分不大
* 使用了特殊的表达式，包括数学运算和函数调用。
* 数据量太小

> 有一种说法是含有 NULL 的列上的索引会失效，不过这个说法并不准确，实际上 MySQL 还是会尽可能用索引的。

## QA:索引与 NULL 的特殊之处

NULL 通常表示 不知道、不存在、不合法等语义。

MySQL 会尽可能使用索引，即使有零值，并且 is null 和 is not null 都可以使用索引。

其次 MySQL 的唯一索引允许有多行的值都是 NULL。也就是说你可以有很多行唯一索引的列的值都是 NULL。但是不管怎么说，使用 NULL 都是一个比较差的实践。

# SQL 优化

![请输入图片描述](./images/2024/09/3281862012.png)

## explain

`explain + sql语句`

**type** ：指的是查询到所需行的方式，从好到坏依次是 system > const > eq_ref > ref > range > index > ALL。
**possible_keys**：候选索引。
**key**：实际用的索引。
**rows**：扫描的行数。
**filtered**：所需数据占 rows 的比例。

## 优化

* **覆盖索引**：将 where 判断的，或者查询要使用的列A,B可以组合索引。
* **order by**：将排序加入索引(索引本身就是有序的)。
* **count**：估计值取代精确值，额外表或者 Redis 记录总数。
  分布式事务不一致的话，如果短时间内业务可以接受，可以通过异步刷新 redis 的数量，也可以用 Canal 之类的工具监听 MySQL binlog 来刷新总数。
* **索引提示**：使用指定索引。FORCE INDEX、USE INDEX 和 IGNORE INDEX。
* **where 替换 having**：一般来说，数据库都是先根据 WHERE 条件找到候选的列，再根据 HAVING 条件进行二次过滤。 可以提前过滤减少查询时间。

# 数据库锁

![请输入图片描述](./images/2024/09/3401170950.jpg)

在 MySQL 的 **InnoDB** 引擎里面，锁是借助**索引**来实现的。或者说，加锁锁住的其实是索引项，更加具体地来说，就是锁住了**叶子节点** 。

**锁的释放时机**：只有在执行 Rollback 或者 Commit 的时候，锁才会被释放掉。

## 锁的类型

### 乐观锁和悲观锁

* 乐观锁是直到要修改数据的时候，才检测数据是否已经被别人修改过。
* 悲观锁是在初始时刻就直接加锁保护好临界资源

### 行锁与表锁

**行锁**：锁住一行或者多行。(借助索引来实现的，如果没有命中任何索引，则只能使用表锁)

**表锁**：锁住整个表。

### 共享锁和排他锁

* 共享锁是指一个线程加锁之后，其他线程还是可以继续加同类型的锁。
* 排它锁是指一个线程加锁之后，其他线程就不能再加锁了。

可以理解为 读写锁，读(共享)，写(排他)。

### 意向锁

意向锁相当于一个信号，就是告诉别人我要加锁了，所以意向锁并不是一个真正物理意义上的锁。

它能和排他锁结合，意向共享锁和意向排他锁。

**使用意向锁能够 提高数据库的并发性能，并且避免死锁问题。**

### 记录锁、间隙锁和临键锁

**记录锁**：锁住了特定的某一条记录的锁。
**间隙锁**：锁住了某一段记录的锁。（左开右开）

**记录锁和记录锁是排它的，但是间隙锁和间隙锁不是排它的** 。

**临键锁**：记录锁 + 间隙锁。**临键锁不仅仅是会用记录锁锁住命中的记录，也会用间隙锁锁住记录之间的空隙** 。（左开右闭）

## QA:介绍一下 MySQL 锁

MySQL 里面的锁机制特别丰富，这里我以 InnoDB 引擎为例。首先，从锁的范围来看，可以分成行锁和表锁。其次，从排它性来看，可以分成排它锁和共享锁。还有意向锁，结合排它性，就分为排它意向锁和共享意向锁。还有三个重要的锁概念，记录锁、间隙锁和临键锁。记录锁，是指锁住某条记录；间隙锁，是指锁住两条记录之间的位置；临键锁可以看成是记录锁与间隙锁的组合情况。

还有一种分类方法，是乐观锁和悲观锁。那么在数据库里面使用乐观锁，本质上是一种应用层面的 CAS 操作。

## QA:临键锁引发的死锁

当两个线程插入两个不存在的 id 时，线程都会产生 (id,supremum] 的临键锁，这个时候就会产生死锁问题，同时等待对方释放掉持有的间隙锁。

**解决方案**

* 不管数据如何，直接插入一个默认数据，插入成功则是不存在，插入失败则是存在，所以不会使用间隙锁，使用了行锁。
* 调整数据库的隔离级别，降低为**已提交读**，就没有间隙锁了。
* 放弃悲观锁，使用乐观锁。CAS 原子操作。

# MVCC 协议

![请输入图片描述](./images/2024/09/3002231155.jpg)

避免读写阻塞延申出 MVCC 协议。

## 隔离级别(从低到高)

1. 读未提交：是指一个事务可以看到另外一个事务尚未提交的修改。
2. 读已提交：是指一个事务只能看到已经提交的事务的修改。 这意味着**如果在事务执行过程中有别的事务提交了，那么事务还是能够看到别的事务最新 提交的修改。**
3. 可重复读：是指在这一个事务内部读同一个数据多次，读到的结果都是同一个。这意味着即便**在事务执行过程中有别的事务提交，这个事务依旧看不到别的事务提交的修改** 。这是 MySQL 默认的隔离级别。
4. 串行化：是指事务对数据的读写都是串行化的。

## 异常

* 脏读：读到了别的事务还没有提交的数据。之所以叫做“脏”读，就是因为未提交数据可能会被回滚掉。
* 不可重复读：一个事务执行过程中，对同一行数据读到的结果不同。
* 幻读：事务执行过程中，别的事务插入了新的数据并且提交了，然后事务在后续步骤中读到了这个新的数据。

![请输入图片描述](./images/2024/09/3092940619.jpg)

**理论上来说可重复读是没有解决幻读的** 。但是 MySQL 因为使用了临键锁，因此它的可重复读隔离级别已经解决了幻读问题。

## 快照读和当前读

* 快照读就是在事务开始的时候创建 了一个数据的快照，在整个事务过程中都读这个快照
* 当前读，则是每次都去读最新数 据。MySQL 在可重复读这个隔离级别下，查询的执行效果和快照读非常接近。

## Read View

Read View 只能用于 **读已提交**和**可重复读**。

* 读已提交：每次发起查询都会创建一个新的 Read View。
* 可重复读：事务开始时，创建 Read View。

## QA:什么是 MCCC ?

MVCC 是 MySQL InnoDB 引擎用于控制数据并发访问的协议。MV 借助于版本链来实现的。在 InnoDB 引擎里面，每一行都有两个额外的列，一 个是 trx_id，代表的是修改这一行数据的事务 ID。另外一个是 r 的是回滚指针。InnoDB 引擎通过回滚指针，将数据的不同版本串联在一起， 也就是版本链。这些串联起来的历史版本，被放到了 undolog 里面。当某一个 事务发起查询的时候，MVCC 会根据事务的隔离级别来生成不同的 Read View，从而控制事务查询最终得到的结果。

# 数据库事务

![请输入图片描述](./images/2024/09/3881946703.jpg)

## undo log(回滚日志)

记录日志，相反操作来恢复数据库

## redo log(操作日志)

innoDB 引擎写数据时先修改内存的数据同时写redo log，然后刷磁盘。如果此时G了，可以通过 redo log来写入。

## ACID

事务的 ACID 特性是指原子性（Atomicity）、一致性 （Consistency）、隔离性 （Isolation）还有持久性（Durability）。

* 原子性：事务是一个不可分割的整体，它在执行过程中不能被中断或推迟，它的所有操作 都必须一次性执行，要么都成功，要么都失败。
* 一致性：事务执行的结果必须满足数据约束条件，不会出现矛盾的结果。注意这里的一致 性和我们讨论的分布式环境下的一致性语义有所差别，后者强调的是不同数据源之间数据 一致。
* 隔离性：事务在执行的时候可以隔离其他事务的干扰，也就是不同事务之间不会相互影 响。
* 持久性：事务执行的结果必须保证在数据库里永久保存，即使系统出现故障或者数据库被 删除，事务的结果也不会丢失。

# 主键生成算法

![请输入图片描述](./images/2024/09/3398729439.jpg)

## UUID

### 弊端

* 过长
* UUID 不是递增的

### 页分裂

UUID 最大的缺陷是它产生的 ID 不是递增的。一般来说，我们倾向于在数据库中使用自增主键，因为这样可以迫使数据库的树朝着一个方向增长，而不会造成中间叶节点分裂，这样插入性能最好。而整体上 UUID 生成的 ID 可以看作是随机，那么就会导致数据往页中间插入，引起更加频繁地页分裂，在糟糕的情况下，这种分裂可能引起连锁反应，整棵树的树形结构都会受到影响。所以我们普遍倾向于采用递增的主键。

### **顺序读**

自增主键还有一个好处，就是数据会有更大的概率按照主键的大小排序，两条主键相近的记录，在磁盘上位置也是相近的。那么可以预计，在范围查询的时候，我们能够更加充分地利用到磁盘的顺序读特性。

## 数据库自增(设置步长)

经过分库分表之后我有十个表，那么我可以让每一个表按照步长来生成自增 ID。比如说第一个表就是生成 1、11、21、31 这种 ID，第二个表就是生成 2、12、22、32 这种 ID。

## 雪花算法

雪花算法采用 64 位来表示一个 ID，其中 1 比特保留，41 比特表示**时间戳**， 10 比特作为**机器 ID**，12 比特作为**序列号**。

### 序列号耗尽

* 12比特不够用，从时间戳拿比特增加到序列号上
* 等待下一时刻继续生成(限流)

一般来说可以考虑加长序列号的长度，比如说缩减时间戳，然后挪给序列号 ID。当然也可以更加简单粗暴地将 64 位的 ID 改成 96 位的 ID，那么序列号 ID 就可以有三四十位，即便是国际大厂也不可能用完了。不过，彻底的兜底方 案还是要有的。我们可以考虑引入类似限流的做法，在当前时刻的 ID 已经耗尽 之后，可以让业务方等一下。我们的时间戳一般都是毫秒数，那么业务方最多 就会等一毫秒。

### 数据堆积

QA:你设想这么一个场景：你的分库分表是按照 ID 除以 32 的余数来进行的，那么如果你的业务 非常低频，以至于每一个时刻都只生成了尾号为 1 的 ID，那么是不是所有的数据都分到了一 张表里面呢？

在低频场景下，很容易出现序列号几乎没有增长，从而导致数据在经过分库分 表之后只落到某一张表里面的情况。为了解决这种问题，可以考虑这么做，序 列号部分不再是从 0 开始增长，而是从一个随机数开始增长。还有一个策略就 是序列号从上一时刻的序列号开始增长，但是如果上一时刻序列号已经很大! 了，那么就可以退化为从 0 开始增长。这样的话要比随机数更可控一点，并且 性能也要更好一点。

## **主键内嵌分库分表键**

大多数时候，我们会面临一个问题，就是分库分表的键和主键并不是同一个。 比如说在 C 端的订单分库分表，我们可以采用买家 ID 来进行分库分表。但是 一些业务场景，比如说查看订单详情，可能是根据主键又或者是根据订单 SN 来查找的。

那么我们可以考虑借鉴雪花算法的设计，将主键生成策略和分库分表键结合在 一起，也就是说在主键内部嵌入分库分表键。例如，我们可以这样设计订单 ID 的生成策略，在这里我们假设分库分表用的是买家 ID 的后四位。第一段依旧是 采用时间戳，但是第二段我们就换成了这个买家后四位，第三段我们采用随机数。

普遍情况下，我们都是用买家 ID 来查询对应的订单信息。在别的场景下，比如 说我们只有一个订单 ID，这种时候我们可以取出订单 ID 里嵌入进去的买家 ID 后四位，来判断数据存储在哪个库、哪个表。类似的设计还有答题记录按照答 题者 ID 来分库分表，但是答题记录 ID 本身可以嵌入这个答题者 ID 中用于分 库分表的部分。

# 分库分表分页

## 分库分表

三种算法

1. 哈希分库分表：ID 取余
2. 范围分库分表：按照 ID 范围，日期范围
3. 中间表：引入一个中间表来记录映射关系

# 分布式事务，如何同时保证分库分表、ACID和高性能？
